"""create datasets table

Revision ID: 118f85d483dd
Revises: 
Create Date: 2025-10-07 22:37:29.210588

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '118f85d483dd'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('datasets',
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique dataset identifier'),
    sa.Column('name', sa.String(length=255), nullable=False, comment='Dataset name'),
    sa.Column('source', sa.String(length=50), nullable=False, comment='Source type: HuggingFace, Local, or Custom'),
    sa.Column('hf_repo_id', sa.String(length=255), nullable=True, comment='HuggingFace repository ID'),
    sa.Column('status', sa.Enum('DOWNLOADING', 'PROCESSING', 'READY', 'ERROR', name='dataset_status_enum'), nullable=False, comment='Current processing status'),
    sa.Column('progress', sa.Float(), nullable=True, comment='Download/processing progress (0-100)'),
    sa.Column('error_message', sa.Text(), nullable=True, comment='Error message if status is ERROR'),
    sa.Column('raw_path', sa.String(length=512), nullable=True, comment='Path to raw dataset files'),
    sa.Column('tokenized_path', sa.String(length=512), nullable=True, comment='Path to tokenized dataset (Arrow format)'),
    sa.Column('num_samples', sa.Integer(), nullable=True, comment='Total number of samples'),
    sa.Column('num_tokens', sa.BigInteger(), nullable=True, comment='Total number of tokens'),
    sa.Column('avg_seq_length', sa.Float(), nullable=True, comment='Average sequence length in tokens'),
    sa.Column('vocab_size', sa.Integer(), nullable=True, comment='Vocabulary size (unique tokens)'),
    sa.Column('size_bytes', sa.BigInteger(), nullable=True, comment='Total size in bytes'),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Additional metadata (splits, features, etc.)'),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False, comment='Record creation timestamp'),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False, comment='Record last update timestamp'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_datasets_created_at', 'datasets', ['created_at'], unique=False)
    op.create_index('idx_datasets_source', 'datasets', ['source'], unique=False)
    op.create_index('idx_datasets_status', 'datasets', ['status'], unique=False)
    # GIN index for JSONB metadata queries
    op.create_index('idx_datasets_metadata_gin', 'datasets', ['metadata'], unique=False, postgresql_using='gin')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_datasets_metadata_gin', table_name='datasets', postgresql_using='gin')
    op.drop_index('idx_datasets_status', table_name='datasets')
    op.drop_index('idx_datasets_source', table_name='datasets')
    op.drop_index('idx_datasets_created_at', table_name='datasets')
    op.drop_table('datasets')
    # ### end Alembic commands ###
